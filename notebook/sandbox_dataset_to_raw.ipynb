{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app\n"
     ]
    }
   ],
   "source": [
    "%cd '/app'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "sys.path.append('/app/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "load('src/dataset/symbolic_utils.sage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader.data import _load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_to_poly(seq, ring):\n",
    "    monoms = seq.split('+')\n",
    "    d = {}\n",
    "    for monom in monoms:\n",
    "       m = monom.split()\n",
    "       if '/' in m[0]:\n",
    "         a, slash, b = m[:3]\n",
    "         assert (slash == '/')\n",
    "         coeff = f'{a[1:]}/{b[1:]}'\n",
    "       else:\n",
    "         coeff = m[0][1:]   \n",
    "         ex = m[1:]\n",
    "         d[tuple([int(ei[1:]) for ei in ex])] = float(coeff)\n",
    "      \n",
    "    return ring(d)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'shape'\n",
    "\n",
    "n, field = 2, 'GF7'\n",
    "data_name = f'{task}_n={n}_field={field}'\n",
    "data_path = f'data/{task}/{data_name}/data_{field}_n={n}.test.lex.infix'\n",
    "\n",
    "dataset = _load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'C2 E3 E0 + C4 E2 E4 + C5 E2 E3 + C1 E2 E2 + C4 E2 E1 + C2 E2 E0 + C1 E0 E5 + C6 E0 E4 + C2 E0 E3 + C2 E0 E1 + C6 E0 E0 [SEP] C5 E3 E2 + C2 E3 E0 + C3 E2 E6 + C2 E2 E5 + C3 E2 E4 + C1 E2 E3 + C6 E2 E2 + C4 E2 E1 + C2 E2 E0 + C1 E1 E0 + C6 E0 E7 + C1 E0 E6 + C6 E0 E5 + C1 E0 E4 + C6 E0 E3 + C5 E0 E2 + C4 E0 E1',\n",
       " 'target': 'C1 E1 E0 + C2 E0 E4 + C6 E0 E3 + C4 E0 E2 + C2 E0 E1 + C1 E0 E0 [SEP] C1 E0 E5 + C6 E0 E4 + C2 E0 E3 + C2 E0 E1 + C6 E0 E0',\n",
       " 'input_mask': None,\n",
       " 'target_mask': None}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C5 E3 E2 + C2 E3 E0 + C3 E2 E6 + C2 E2 E5 + C3 E2 E4 + C1 E2 E3 + C6 E2 E2 + C4 E2 E1 + C2 E2 E0 + C1 E1 E0 + C6 E0 E7 + C1 E0 E6 + C6 E0 E5 + C1 E0 E4 + C6 E0 E3 + C5 E0 E2 + C4 E0 E1'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_dataset(dataset, ring):\n",
    "    raw_dataset = []\n",
    "    for sample in dataset:\n",
    "        Fstr, Gstr = sample['input'], sample['target']\n",
    "        F, G = [], []\n",
    "        \n",
    "        for fstr in Fstr.split(' [SEP] '):\n",
    "            f = sequence_to_poly(fstr, ring)\n",
    "            F.append(f)\n",
    "        \n",
    "        for gstr in Gstr.split(' [SEP] '):\n",
    "            g = sequence_to_poly(gstr, ring)\n",
    "            G.append(g)\n",
    "            \n",
    "        raw_dataset.append((F, G))\n",
    "\n",
    "    return raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ring = PolynomialRing(GF(7), 'x', n, order='lex')\n",
    "raw_dataset = get_raw_dataset(dataset, ring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2*x0^3 - 3*x0^2*x1^4 - 2*x0^2*x1^3 + x0^2*x1^2 - 3*x0^2*x1 + 2*x0^2 + x1^5 - x1^4 + 2*x1^3 + 2*x1 - 1,\n",
       "  -2*x0^3*x1^2 + 2*x0^3 + 3*x0^2*x1^6 + 2*x0^2*x1^5 + 3*x0^2*x1^4 + x0^2*x1^3 - x0^2*x1^2 - 3*x0^2*x1 + 2*x0^2 + x0 - x1^7 + x1^6 - x1^5 + x1^4 - x1^3 - 2*x1^2 - 3*x1],\n",
       " [x0 + 2*x1^4 - x1^3 - 3*x1^2 + 2*x1 + 1, x1^5 - x1^4 + 2*x1^3 + 2*x1 - 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2*x0^3*x1^2 + 2*x0^3 + 3*x0^2*x1^6 + 2*x0^2*x1^5 + 3*x0^2*x1^4 + x0^2*x1^3 - x0^2*x1^2 - 3*x0^2*x1 + 2*x0^2 + x0 - x1^7 + x1^6 - x1^5 + x1^4 - x1^3 - 2*x1^2 - 3*x1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ring = PolynomialRing(GF(7), 'x', n, order='lex')\n",
    "\n",
    "p = dataset[0]['input'].split(' [SEP] ')[-1]\n",
    "\n",
    "sequence_to_poly(p, ring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'shape'\n",
    "encoding = 'standard'\n",
    "\n",
    "n, field = 2, 'GF7'\n",
    "data_name = f'{task}_n={n}_field={field}_init'\n",
    "data_path = f'data/{task}/{data_name}/data_{field}_n={n}.test.lex.infix'\n",
    "\n",
    "data_config_path = f'config/{data_name}.yaml'\n",
    "_save_path = f'{field}_n={n}_ep=8_bs=16'\n",
    "save_path = f'results/{task}/{encoding}_embedding_init/{_save_path}'\n",
    "# save_path = f'results/{task}/{encoding}/dryrun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = load_pretrained_bag(save_path)\n",
    "config, model, tokenizer = bag['config'], bag['model'], bag['tokenizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.36s/it]\n"
     ]
    }
   ],
   "source": [
    "from loader.data import _load_data\n",
    "from loader.data import SimpleDataCollator\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 500\n",
    "dataloader = data_path\n",
    "disable_tqdm = False\n",
    "max_length = 10000\n",
    "\n",
    "if isinstance(dataloader, str):\n",
    "    dataset = _load_data(dataloader)\n",
    "    dc = SimpleDataCollator(tokenizer)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=dc, shuffle=False)\n",
    "\n",
    "# load model    \n",
    "if isinstance(model, str):\n",
    "    bag = load_pretrained_bag(model)\n",
    "    config, model, tokenizer = bag['config'], bag['model'], bag['tokenizer']\n",
    "else:\n",
    "    assert(tokenizer is not None)\n",
    "\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    hits = []\n",
    "    dataloader = tqdm(dataloader, disable=disable_tqdm)  if not disable_tqdm else dataloader\n",
    "    for batch in dataloader:\n",
    "        max_length = min(max_length, batch['labels'].shape[1] + 1)\n",
    "        outputs = model.greedy_generate(batch['encoder_input'].cuda(), max_length=max_length, encoder_padding_mask=batch['encoder_padding_mask'].cuda())\n",
    "        pred = tokenizer.batch_decode(outputs.cpu().numpy(), skip_special_tokens=True)\n",
    "        target = tokenizer.batch_decode(batch['labels'], skip_special_tokens=True)\n",
    "        \n",
    "        hits += [p == t for p, t in zip(pred, target)]\n",
    "        \n",
    "    ret = {'acc': np.array(hits, dtype=float).mean(), 'hits': hits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.579"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, True, True, True, False, True, False, True, False]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret['hits'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['encoder_input', 'decoder_input', 'encoder_padding_mask', 'decoder_padding_mask', 'labels'])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch  = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.6 s, sys: 17.1 ms, total: 22.6 s\n",
      "Wall time: 1.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "outputs = model.greedy_generate(batch['encoder_input'].cuda(), \n",
    "                                encoder_attention_mask=None,\n",
    "                                encoder_padding_mask=batch['encoder_padding_mask'].cuda(),\n",
    "                                max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[36,  4, 12, 11, 32,  4, 11, 11, 40,  4, 11, 12, 38, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [36,  4, 12, 11, 32,  4, 11, 13, 40,  4, 11, 14, 32,  5, 11, 13, 32,  5,\n",
       "         11, 12, 32,  5, 11, 11, 38, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [36,  4, 12, 11, 32,  5, 11, 11, 40,  4, 11, 15, 38, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [36,  4, 12, 11, 32,  8, 11, 14, 32,  9, 11, 12, 32,  9, 11, 11, 40,  4,\n",
       "         11, 15, 32,  9, 11, 14, 32,  8, 11, 13, 32,  8, 11, 12, 38, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36]], device='cuda:0')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4, 12, 11, 32,  4, 11, 11, 40,  4, 11, 12, 38, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [ 4, 12, 11, 32,  4, 11, 13, 40,  4, 11, 14, 32,  8, 11, 11, 38, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [ 4, 12, 11, 32,  5, 11, 11, 40,  4, 11, 15, 38, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [ 4, 12, 11, 32,  8, 11, 14, 32,  9, 11, 12, 32,  9, 11, 11, 40,  4, 11,\n",
       "         15, 32,  9, 11, 14, 32,  8, 11, 13, 32,  8, 11, 12, 38, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels'][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C1 E1 E0 + C1 E0 E2 [SEP] C1 E0 E3 + C2 E0 E2 + C2 E0 E1 + C2 E0 E0'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(outputs.cpu().numpy(), skip_special_tokens=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C1 E1 E0 + C1 E0 E2 [SEP] C1 E0 E3 + C5 E0 E0'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(batch['labels'], skip_special_tokens=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C1 E1 E0 + C1 E0 E2 [SEP] C1 E3 E1 + C1 E2 E3 + C5 E2 E2 + C5 E1 E4 + C1 E1 E2 + C5 E1 E1 + C3 E1 E0 + C6 E0 E3 + C3 E0 E2 + C2 E0 E1 + C5 E0 E0 [SEP] C4 E5 E2 + C4 E4 E4 + C4 E4 E1 + C4 E3 E3 + C6 E3 E2 + C5 E3 E1 + C3 E2 E5 + C3 E2 E4 + C5 E2 E3 + C3 E2 E1 + C1 E2 E0 + C2 E1 E4 + C1 E1 E3 + C1 E1 E2 + C2 E0 E4 + C5 E0 E3 + C1 E0 E2 + C3 E0 E1 + C2 E0 E0'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(batch['encoder_input'], skip_special_tokens=True)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'E9': 20,\n",
       " 'C0': 3,\n",
       " 'E12': 23,\n",
       " '[UNK]': 41,\n",
       " '/': 35,\n",
       " 'E10': 21,\n",
       " 'E2': 13,\n",
       " 'C2': 5,\n",
       " 'E17': 28,\n",
       " '[SEP]': 40,\n",
       " '^': 34,\n",
       " 'E14': 25,\n",
       " 'E18': 29,\n",
       " '</s>': 38,\n",
       " '<s>': 37,\n",
       " 'E3': 14,\n",
       " '+': 32,\n",
       " 'C3': 6,\n",
       " 'E8': 19,\n",
       " 'E13': 24,\n",
       " 'E0': 11,\n",
       " 'E5': 16,\n",
       " '[PAD]': 36,\n",
       " 'E4': 15,\n",
       " 'C4': 7,\n",
       " 'E20': 31,\n",
       " 'C1': 4,\n",
       " 'C5': 8,\n",
       " '[C]': 2,\n",
       " 'C6': 9,\n",
       " '[E]': 10,\n",
       " 'E19': 30,\n",
       " '[CLS]': 39,\n",
       " '*': 33,\n",
       " 'E16': 27,\n",
       " 'E1': 12,\n",
       " 'E11': 22,\n",
       " 'x0': 0,\n",
       " 'x1': 1,\n",
       " 'E15': 26,\n",
       " 'E7': 18,\n",
       " 'E6': 17}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 10.4",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
