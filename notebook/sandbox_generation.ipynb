{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd '/app'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "sys.path.append('/app/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader.data import _load_data, SimpleDataCollator, HybridDataCollator, BartDataCollator, BartPlusDataCollator, get_datacollator\n",
    "from loader.model import load_model\n",
    "from loader.checkpoint import load_pretrained_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "task ='shape'\n",
    "nvars = 2\n",
    "field ='GF7'\n",
    "encoding_method = 'hybrid'\n",
    "\n",
    "density=0.3\n",
    "\n",
    "data_name = f'{task}_n={nvars}_field={field}'\n",
    "# data_name = f'{task}_n={nvars}_field={field}_density={density}'\n",
    "\n",
    "data_path = f'data/{task}/{data_name}/data_{field}_n={nvars}'\n",
    "data_config_path = f'config/{data_name}.yaml'\n",
    "\n",
    "model = 'bart+'\n",
    "\n",
    "group = f'{encoding_method}_{model}'\n",
    "_save_path = f'{field}_n={nvars}'\n",
    "# _save_path = f'{field}_n={nvars}_density={density}'\n",
    "save_path = f'results/{task}/{group}/{_save_path}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generation import generation_accuracy, generation, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model bart+ from results/shape/hybrid_bart+/GF7_n=2\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from misc.utils import to_cuda\n",
    "import yaml, argparse\n",
    "with open(os.path.join(save_path, 'params.yaml'), 'r') as f:\n",
    "    params = yaml.safe_load(f)\n",
    "    params = argparse.Namespace(**params)\n",
    "\n",
    "bag = load_pretrained_bag(save_path, cuda=True)\n",
    "model, tokenizer = bag['model'], bag['tokenizer']\n",
    "model_name = params.model\n",
    "print(f'Loaded model {model_name} from {save_path}')\n",
    "\n",
    "data_encoding = 'infix+' if params.encoding_method == 'hybrid' and params.field == 'QQ' else 'infix'\n",
    "testset     = _load_data(f'{params.data_path}.test.lex.{data_encoding}')\n",
    "dc = get_datacollator(params.model)(tokenizer, continuous_coefficient=True)\n",
    "# dc = get_datacollator(params.model)(tokenizer)\n",
    "testloader = DataLoader(testset, batch_size=8, collate_fn=dc, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc.utils import to_cuda\n",
    "batch = next(iter(testloader))\n",
    "batch = to_cuda(batch)\n",
    "preds = generation(model, model_name, batch, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = tokenizer.batch_decode(batch['labels'], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.generation import support_eq, coeffs_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_eq(preds[0], batch['labels_for_regression'][0].detach().cpu().numpy(), th=0.4999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.5, 'support_acc': 0.75}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(preds, targets, \n",
    "               labels_for_regression=batch['labels_for_regression'].detach().cpu().numpy(),\n",
    "               th=0.4999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:36<00:00,  3.40it/s]\n"
     ]
    }
   ],
   "source": [
    "results = generation_accuracy(model_name,\n",
    "                    model, \n",
    "                    testloader, \n",
    "                    batch_size=500, \n",
    "                    max_length=128,\n",
    "                    tokenizer=tokenizer, \n",
    "                    th=0.4999, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:27<00:00, 13.98s/it]\n"
     ]
    }
   ],
   "source": [
    "results = generation_accuracy(params.model,\n",
    "                    save_path, \n",
    "                    data_path + '.test.lex.infix', \n",
    "                    batch_size=500, \n",
    "                    max_length=128,\n",
    "                    tokenizer=tokenizer, \n",
    "                    th=0.4999, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['acc', 'support_acc', 'hits', 'support_hits', 'batch_runtimes', 'runtime_per_batch'])\n",
      "0.28827040481567384\n"
     ]
    }
   ],
   "source": [
    "print(results.keys())\n",
    "print(results['runtime_per_batch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False True\n"
     ]
    }
   ],
   "source": [
    "hit = preds[0] == targets[0]\n",
    "support_hit = support_eq(preds[0], targets[0])\n",
    "\n",
    "print(hit, support_hit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'coeffs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m coeffs_eq(preds[\u001b[38;5;241m0\u001b[39m], \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcoeffs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m], tokenizer)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'coeffs'"
     ]
    }
   ],
   "source": [
    "coeffs_eq(preds[0], batch['coeffs'][0], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[C] E1 E0 + [C] E0 E1 [SEP] [C] E0 E4 + [C] E0 E0'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C1.0375462770462036 E1 E0 + C3.0773425102233887 E0 E1 [SEP] C1.0411913394927979 E0 E4 + C4.126354217529297 E0 E0'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = get_datacollator('bart+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml, argparse\n",
    "with open(os.path.join(save_path, 'params.yaml'), 'r') as f:\n",
    "    params = yaml.safe_load(f)\n",
    "    params = argparse.Namespace(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loader.checkpoint import load_config, load_pretrained_bag, load_pretrained_model, load_tokenizer\n",
    "model_config = load_config(save_path)\n",
    "tokenizer = load_tokenizer(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = load_pretrained_bag(save_path, cuda=False)\n",
    "model = bag['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(params.model, params, tokenizer=tokenizer, cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for BartForConditionalGeneration:\n\tsize mismatch for final_logits_bias: copying a param with shape torch.Size([1, 36]) from checkpoint, the shape in current model is torch.Size([1, 35]).\n\tsize mismatch for lm_head.weight: copying a param with shape torch.Size([36, 512]) from checkpoint, the shape in current model is torch.Size([35, 512]).\n\tYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BartForConditionalGeneration\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mBartForConditionalGeneration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel.safetensors\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m    \n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_utils.py:4014\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4004\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4005\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   4007\u001b[0m     (\n\u001b[1;32m   4008\u001b[0m         model,\n\u001b[1;32m   4009\u001b[0m         missing_keys,\n\u001b[1;32m   4010\u001b[0m         unexpected_keys,\n\u001b[1;32m   4011\u001b[0m         mismatched_keys,\n\u001b[1;32m   4012\u001b[0m         offload_index,\n\u001b[1;32m   4013\u001b[0m         error_msgs,\n\u001b[0;32m-> 4014\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   4018\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4021\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4022\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4024\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4025\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4026\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4030\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgguf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4031\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4033\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[1;32m   4034\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_utils.py:4559\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path)\u001b[0m\n\u001b[1;32m   4555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize mismatch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_msg:\n\u001b[1;32m   4556\u001b[0m         error_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   4557\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4558\u001b[0m         )\n\u001b[0;32m-> 4559\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unexpected_keys) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   4562\u001b[0m     archs \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39marchitectures \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39marchitectures\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BartForConditionalGeneration:\n\tsize mismatch for final_logits_bias: copying a param with shape torch.Size([1, 36]) from checkpoint, the shape in current model is torch.Size([1, 35]).\n\tsize mismatch for lm_head.weight: copying a param with shape torch.Size([36, 512]) from checkpoint, the shape in current model is torch.Size([35, 512]).\n\tYou may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method."
     ]
    }
   ],
   "source": [
    "# from transformers import BartForConditionalGeneration\n",
    "# model = BartForConditionalGeneration.from_pretrained(os.path.join(save_path, f'model.safetensors'), config=model_config, use_safetensors=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params.encoding_method == 'hybrid' and params.field == 'QQ':\n",
    "    data_encoding = 'infix+'\n",
    "else:\n",
    "    data_encoding = 'infix'\n",
    "\n",
    "testset     = _load_data(f'{params.data_path}.test.lex.{data_encoding}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_continous_token = params.encoding_method == 'hybrid'    \n",
    "\n",
    "if params.model == 'bart':\n",
    "    dc = BartDataCollator(tokenizer)\n",
    "    label_names = ['labels']\n",
    "\n",
    "elif params.model == 'bart+':\n",
    "    dc = BartPlusDataCollator(tokenizer, continuous_coefficient=use_continous_token)\n",
    "    \n",
    "    if use_continous_token:\n",
    "        label_names = ['labels', 'labels_for_regression']\n",
    "    else:\n",
    "        label_names = ['labels']\n",
    "else:\n",
    "    raise ValueError(f'unknown model: {params.model}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(testset, batch_size=params.batch_size, shuffle=False, collate_fn=dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.cuda()\n",
    "\n",
    "batch = next(iter(testloader))\n",
    "# for k in batch:\n",
    "#     if isinstance(batch[k], torch.Tensor):\n",
    "#         batch[k] = batch[k].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([16, 273])\n",
      "attention_mask torch.Size([16, 273])\n",
      "decoder_input_ids torch.Size([16, 40])\n",
      "decoder_attention_mask torch.Size([16, 40])\n",
      "labels torch.Size([16, 40])\n",
      "labels_for_regression torch.Size([16, 40, 1])\n",
      "input_continuous_labels torch.Size([16, 273, 1])\n",
      "target_continuous_labels torch.Size([16, 40, 1])\n"
     ]
    }
   ],
   "source": [
    "for k in batch:\n",
    "    print(k, batch[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits.argmax(dim=-1)[0] == batch['labels'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "_batch = [sample for sample in testset][:10]\n",
    "input_texts = [item[\"input\"] for item in _batch]\n",
    "target_texts = [item[\"target\"] for item in _batch]\n",
    "# input_encodings['attention_mask'].bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "WordLevel error: Missing [UNK] token from the vocabulary",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m input_encodings \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlongest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m target_encodings \u001b[38;5;241m=\u001b[39m tokenizer(target_texts, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongest\u001b[39m\u001b[38;5;124m'\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3016\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3014\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   3015\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 3016\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3018\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3104\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3099\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3100\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3101\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3102\u001b[0m         )\n\u001b[1;32m   3103\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[0;32m-> 3104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3106\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3122\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3123\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3124\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3125\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[1;32m   3127\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   3128\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3146\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3147\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3306\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3296\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   3297\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   3298\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   3299\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3303\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3304\u001b[0m )\n\u001b[0;32m-> 3306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3308\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3324\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:529\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mencode_special_tokens \u001b[38;5;241m!=\u001b[39m split_special_tokens:\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mencode_special_tokens \u001b[38;5;241m=\u001b[39m split_special_tokens\n\u001b[0;32m--> 529\u001b[0m encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_pretokenized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;66;03m# Convert encoding to dict\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;66;03m# `Tokens` has type: Tuple[\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;66;03m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;66;03m#                       List[EncodingFast]\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;66;03m#                    ]\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[1;32m    541\u001b[0m tokens_and_encodings \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_encoding(\n\u001b[1;32m    543\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m encoding \u001b[38;5;129;01min\u001b[39;00m encodings\n\u001b[1;32m    553\u001b[0m ]\n",
      "\u001b[0;31mException\u001b[0m: WordLevel error: Missing [UNK] token from the vocabulary"
     ]
    }
   ],
   "source": [
    "input_encodings = tokenizer(input_texts, padding='longest', return_tensors='pt')\n",
    "target_encodings = tokenizer(target_texts, padding='longest', return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_encodings['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbatch\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;66;43;03m#   num_beams=1, max_length=500, \u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;66;43;03m#   do_sample=False, \u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_continuous_labels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mcontinuous_token_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m[C]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m      7\u001b[0m                      \u001b[38;5;66;03m#   early_stopping=True)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m preds_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(preds, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/app/src/loader/models/bart.py:241\u001b[0m, in \u001b[0;36mBartForConditionalGenerationPlus.generate\u001b[0;34m(self, input_ids, input_continuous_labels, attention_mask, max_length, continuous_token_ids, quantize_fn)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_length):\n\u001b[1;32m    240\u001b[0m     decoder_inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_embedding(dec_input[\u001b[38;5;241m~\u001b[39mfinished], target_continuous_labels[\u001b[38;5;241m~\u001b[39mfinished])\n\u001b[0;32m--> 241\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m~\u001b[39;49m\u001b[43mfinished\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m~\u001b[39;49m\u001b[43mfinished\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m~\u001b[39;49m\u001b[43mfinished\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(outputs[\u001b[38;5;241m0\u001b[39m])[:, i, :]  \u001b[38;5;66;03m# not i+1\u001b[39;00m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_continuous_tokens:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:1528\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1521\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m BaseModelOutput(\n\u001b[1;32m   1522\u001b[0m         last_hidden_state\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   1523\u001b[0m         hidden_states\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1524\u001b[0m         attentions\u001b[38;5;241m=\u001b[39mencoder_outputs[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(encoder_outputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1525\u001b[0m     )\n\u001b[1;32m   1527\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1528\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1544\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs \u001b[38;5;241m+\u001b[39m encoder_outputs\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:1325\u001b[0m, in \u001b[0;36mBartDecoder.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         encoder_attention_mask \u001b[38;5;241m=\u001b[39m _prepare_4d_attention_mask(\n\u001b[1;32m   1321\u001b[0m             encoder_attention_mask, inputs_embeds\u001b[38;5;241m.\u001b[39mdtype, tgt_len\u001b[38;5;241m=\u001b[39minput_shape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1322\u001b[0m         )\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;66;03m# embed positions\u001b[39;00m\n\u001b[0;32m-> 1325\u001b[0m positions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_positions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1326\u001b[0m positions \u001b[38;5;241m=\u001b[39m positions\u001b[38;5;241m.\u001b[39mto(inputs_embeds\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   1328\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m positions\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:116\u001b[0m, in \u001b[0;36mBartLearnedPositionalEmbedding.forward\u001b[0;34m(self, input_ids, past_key_values_length)\u001b[0m\n\u001b[1;32m    111\u001b[0m bsz, seq_len \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    112\u001b[0m positions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\n\u001b[1;32m    113\u001b[0m     past_key_values_length, past_key_values_length \u001b[38;5;241m+\u001b[39m seq_len, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    114\u001b[0m )\u001b[38;5;241m.\u001b[39mexpand(bsz, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:2264\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2258\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2259\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2260\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2261\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2262\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2263\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "preds = model.generate(batch['input_ids'],  \n",
    "                     #   num_beams=1, max_length=500, \n",
    "                     #   do_sample=False, \n",
    "                     batch['input_continuous_labels'],\n",
    "                     continuous_token_ids=[tokenizer.vocab['[C]']],\n",
    "                       attention_mask=batch['attention_mask'],) \n",
    "                     #   early_stopping=True)\n",
    "preds_text = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "labels_t = tokenizer.batch_decode(batch['labels'], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 96])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [16, 96] at index 1 does not match the shape of the indexed tensor [16, 108] at index 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m no_pad \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mpad_token_id\n\u001b[0;32m----> 2\u001b[0m hits \u001b[38;5;241m=\u001b[39m \u001b[43mpreds\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mno_pad\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m][no_pad]\n\u001b[1;32m      3\u001b[0m hits\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [16, 96] at index 1 does not match the shape of the indexed tensor [16, 108] at index 1"
     ]
    }
   ],
   "source": [
    "no_pad = batch['labels'] != tokenizer.pad_token_id\n",
    "hits = preds[:, 1:][no_pad] == batch['labels'][no_pad]\n",
    "hits.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 14, 13, 13, 13, 34,  8, 13, 13, 13, 16, 34,  9, 13, 13, 13, 15, 42,\n",
       "         6, 13, 14, 13, 13, 34,  7, 13, 13, 13, 16, 34,  6, 13, 13, 13, 15, 34,\n",
       "         9, 13, 13, 13, 14, 42,  6, 13, 13, 14, 13, 34,  7, 13, 13, 13, 16, 34,\n",
       "        10, 13, 13, 13, 13, 42,  6, 13, 13, 13, 17, 34,  9, 13, 13, 13, 14, 40,\n",
       "        38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38,\n",
       "        38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38,\n",
       "        38, 38, 38, 38, 38, 38])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = tokenizer.batch_decode(batch['input_ids'], skip_special_tokens=True)\n",
    "preds_text = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "labels_t = tokenizer.batch_decode(batch['labels'], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[o] pred: C1 E1 E0 E0 E0 + C8 E0 E0 E0 E0 [SEP] C1 E0 E1 E0 E0 + C5 E0 E0 E0 E0 [SEP] C1 E0 E0 E1 E0 + C7 E0 E0 E0 E0 [SEP] C1 E0 E0 E0 E1\n",
      "   label: C1 E1 E0 E0 E0 + C8 E0 E0 E0 E0 [SEP] C1 E0 E1 E0 E0 + C5 E0 E0 E0 E0 [SEP] C1 E0 E0 E1 E0 + C7 E0 E0 E0 E0 [SEP] C1 E0 E0 E0 E1\n",
      "\n",
      "\n",
      "[x] pred: C1 E1 E0 E0 E0 + C11 E0 E0 E0 E4 + C27 E0 E0 E0 E3 + C23 E0 E0 E0 E2 [SEP] C1 E0 E1 E0 E0 + C24 E0 E0 E0 E0 [SEP] C1 E0 E0 E1 E0 + C2 E0 E0 E0 E0 [SEP] C1 E0 E0 E0 E5 + C5 E0 E0 E0 E4 + C20 E0 E0 E0 E2\n",
      "   label: C1 E1 E0 E0 E0 + C11 E0 E0 E0 E4 + C27 E0 E0 E0 E3 + C23 E0 E0 E0 E2 [SEP] C1 E0 E1 E0 E0 + C24 E0 E0 E0 E0 [SEP] C1 E0 E0 E1 E0 + C2 E0 E0 E0 E0 [SEP] C1 E0 E0 E0 E5 + C5 E0 E0 E0 E4 + C25 E0 E0 E0 E2\n",
      "\n",
      "\n",
      "[o] pred: C1 E1 E0 E0 E0 + C29 E0 E0 E0 E1 + C2 E0 E0 E0 E0 [SEP] C1 E0 E1 E0 E0 + C26 E0 E0 E0 E4 + C11 E0 E0 E0 E3 + C6 E0 E0 E0 E1 + C7 E0 E0 E0 E0 [SEP] C1 E0 E0 E1 E0 + C11 E0 E0 E0 E4 + C2 E0 E0 E0 E3 + C2 E0 E0 E0 E2 + C15 E0 E0 E0 E1 [SEP] C1 E0 E0 E0 E5 + C22 E0 E0 E0 E4 + C3 E0 E0 E0 E3\n",
      "   label: C1 E1 E0 E0 E0 + C29 E0 E0 E0 E1 + C2 E0 E0 E0 E0 [SEP] C1 E0 E1 E0 E0 + C26 E0 E0 E0 E4 + C11 E0 E0 E0 E3 + C6 E0 E0 E0 E1 + C7 E0 E0 E0 E0 [SEP] C1 E0 E0 E1 E0 + C11 E0 E0 E0 E4 + C2 E0 E0 E0 E3 + C2 E0 E0 E0 E2 + C15 E0 E0 E0 E1 [SEP] C1 E0 E0 E0 E5 + C22 E0 E0 E0 E4 + C3 E0 E0 E0 E3\n",
      "\n",
      "\n",
      "[x] pred: C1 E1 E0 E0 E0 + C25 E0 E0 E0 E2 + C13 E0 E0 E0 E1 [SEP] C1 E0 E1 E0 E0 + C12 E0 E0 E0 E4 + C20 E0 E0 E0 E3 + C10 E0 E0 E0 E2 + C16 E0 E0 E0 E1 + C10 E0 E0 E0 E0 [SEP] C1 E0 E0 E1 E0 + C23 E0 E0 E0 E4 + C23 E0 E0 E0 E3 + C23 E0 E0 E0 E2 + C16 E0 E0 E0 E1 [SEP] C1 E0 E0 E0 E5 + C29 E0 E0 E0 E4 + C29 E0 E0 E0 E2 + C26 E0 E0 E0 E1\n",
      "   label: C1 E1 E0 E0 E0 + C25 E0 E0 E0 E2 + C13 E0 E0 E0 E1 [SEP] C1 E0 E1 E0 E0 + C12 E0 E0 E0 E4 + C20 E0 E0 E0 E3 + C10 E0 E0 E0 E2 + C16 E0 E0 E0 E1 + C10 E0 E0 E0 E0 [SEP] C1 E0 E0 E1 E0 + C23 E0 E0 E0 E2 + C16 E0 E0 E0 E1 [SEP] C1 E0 E0 E0 E5 + C29 E0 E0 E0 E4 + C29 E0 E0 E0 E2 + C26 E0 E0 E0 E1\n",
      "\n",
      "\n",
      "[o] pred: C1 E1 E0 E0 E0 + C14 E0 E0 E0 E0 [SEP] C1 E0 E1 E0 E0 + C2 E0 E0 E0 E0 [SEP] C1 E0 E0 E1 E0 + C3 E0 E0 E0 E0 [SEP] C1 E0 E0 E0 E1\n",
      "   label: C1 E1 E0 E0 E0 + C14 E0 E0 E0 E0 [SEP] C1 E0 E1 E0 E0 + C2 E0 E0 E0 E0 [SEP] C1 E0 E0 E1 E0 + C3 E0 E0 E0 E0 [SEP] C1 E0 E0 E0 E1\n",
      "\n",
      "\n",
      "[x] pred: C1 E1 E0 E0 E0 + C26 E0 E0 E0 E1 + C13 E0 E0 E0 E0 [SEP] C1 E0 E1 E0 E0 + C11 E0 E0 E0 E3 + C18 E0 E0 E0 E0 [SEP] C1 E0 E0 E1 E0 + C26 E0 E0 E0 E1 + C22 E0 E0 E0 E0 [SEP] C1 E0 E0 E0 E5 + C30 E0 E0 E0 E4 + C20 E0 E0 E0 E3 + C21 E0 E0 E0 E1 + C27 E0 E0 E0 E0\n",
      "   label: C1 E1 E0 E0 E0 + C26 E0 E0 E0 E1 + C13 E0 E0 E0 E0 [SEP] C1 E0 E1 E0 E0 + C11 E0 E0 E0 E3 + C18 E0 E0 E0 E0 [SEP] C1 E0 E0 E1 E0 + C26 E0 E0 E0 E1 + C22 E0 E0 E0 E0 [SEP] C1 E0 E0 E0 E5 + C29 E0 E0 E0 E4 + C20 E0 E0 E0 E3 + C25 E0 E0 E0 E1 + C27 E0 E0 E0 E0\n",
      "\n",
      "\n",
      "[o] pred: C1 E1 E0 E0 E0 + C9 E0 E0 E0 E3 + C16 E0 E0 E0 E0 [SEP] C1 E0 E1 E0 E0 + C26 E0 E0 E0 E3 + C24 E0 E0 E0 E2 + C18 E0 E0 E0 E1 + C18 E0 E0 E0 E0 [SEP] C1 E0 E0 E1 E0 + C23 E0 E0 E0 E3 + C3 E0 E0 E0 E1 + C22 E0 E0 E0 E0 [SEP] C1 E0 E0 E0 E4\n",
      "   label: C1 E1 E0 E0 E0 + C9 E0 E0 E0 E3 + C16 E0 E0 E0 E0 [SEP] C1 E0 E1 E0 E0 + C26 E0 E0 E0 E3 + C24 E0 E0 E0 E2 + C18 E0 E0 E0 E1 + C18 E0 E0 E0 E0 [SEP] C1 E0 E0 E1 E0 + C23 E0 E0 E0 E3 + C3 E0 E0 E0 E1 + C22 E0 E0 E0 E0 [SEP] C1 E0 E0 E0 E4\n",
      "\n",
      "\n",
      "[x] pred: C1 E1 E0 E0 E0 + C24 E0 E0 E0 E2 + C4 E0 E0 E0 E1 [SEP] C1 E0 E1 E0 E0 + C12 E0 E0 E0 E4 + C6 E0 E0 E0 E3 + C11 E0 E0 E0 E1 [SEP] C1 E0 E0 E1 E0 + C26 E0 E0 E0 E4 + C23 E0 E0 E0 E3 + C22 E0 E0 E0 E2 + C29 E0 E0 E0 E0 [SEP] C1 E0 E0 E0 E5 + C1 E0 E0 E0 E2 + C10 E0 E0 E0 E0\n",
      "   label: C1 E1 E0 E0 E0 + C24 E0 E0 E0 E2 + C4 E0 E0 E0 E1 [SEP] C1 E0 E1 E0 E0 + C12 E0 E0 E0 E4 + C6 E0 E0 E0 E3 + C11 E0 E0 E0 E1 [SEP] C1 E0 E0 E1 E0 + C26 E0 E0 E0 E4 + C23 E0 E0 E0 E3 + C22 E0 E0 E0 E2 + C29 E0 E0 E0 E0 [SEP] C1 E0 E0 E0 E5 + C29 E0 E0 E0 E3 + C10 E0 E0 E0 E0\n",
      "\n",
      "\n",
      "[x] pred: C1 E1 E0 E0 E0 + C1 E0 E0 E0 E4 + C22 E0 E0 E0 E2 + C24 E0 E0 E0 E1 + C11 E0 E0 E0 E0 [SEP] C1 E0 E1 E0 E0 + C9 E0 E0 E0 E3 [SEP] C1 E0 E0 E1 E0 + C29 E0 E0 E0 E2 + C1 E0 E0 E0 E1 [SEP] C1 E0 E0 E0 E5 + C22 E0 E0 E0 E4 + C11 E0 E0 E0 E3 + C6 E0 E0 E0 E2 + C1 E0 E0 E0 E1\n",
      "   label: C1 E1 E0 E0 E0 + C1 E0 E0 E0 E4 + C22 E0 E0 E0 E2 + C24 E0 E0 E0 E1 + C11 E0 E0 E0 E0 [SEP] C1 E0 E1 E0 E0 + C27 E0 E0 E0 E3 [SEP] C1 E0 E0 E1 E0 + C29 E0 E0 E0 E2 + C1 E0 E0 E0 E1 [SEP] C1 E0 E0 E0 E5 + C22 E0 E0 E0 E4 + C11 E0 E0 E0 E3 + C6 E0 E0 E0 E2 + C1 E0 E0 E0 E1\n",
      "\n",
      "\n",
      "[o] pred: C1 E1 E0 E0 E0 + C8 E0 E0 E0 E0 [SEP] C1 E0 E1 E0 E0 + C15 E0 E0 E0 E0 [SEP] C1 E0 E0 E1 E0 + C19 E0 E0 E0 E0 [SEP] C1 E0 E0 E0 E1\n",
      "   label: C1 E1 E0 E0 E0 + C8 E0 E0 E0 E0 [SEP] C1 E0 E1 E0 E0 + C15 E0 E0 E0 E0 [SEP] C1 E0 E0 E1 E0 + C19 E0 E0 E0 E0 [SEP] C1 E0 E0 E0 E1\n",
      "\n",
      "\n",
      "[o] pred: C1 E1 E0 E0 E0 + C3 E0 E0 E0 E0 [SEP] C1 E0 E1 E0 E0 + C22 E0 E0 E0 E0 [SEP] C1 E0 E0 E1 E0 + C28 E0 E0 E0 E0 [SEP] C1 E0 E0 E0 E1\n",
      "   label: C1 E1 E0 E0 E0 + C3 E0 E0 E0 E0 [SEP] C1 E0 E1 E0 E0 + C22 E0 E0 E0 E0 [SEP] C1 E0 E0 E1 E0 + C28 E0 E0 E0 E0 [SEP] C1 E0 E0 E0 E1\n",
      "\n",
      "\n",
      "[x] pred: C1 E1 E0 E0 E0 + C17 E0 E0 E0 E2 + C17 E0 E0 E0 E0 [SEP] C1 E0 E1 E0 E0 + C24 E0 E0 E0 E2 + C11 E0 E0 E0 E1 + C22 E0 E0 E0 E0 [SEP] C1 E0 E0 E1 E0 + C13 E0 E0 E0 E2 + C8 E0 E0 E0 E1 + C7 E0 E0 E0 E0 [SEP] C1 E0 E0 E0 E3 + C8 E0 E0 E0 E1\n",
      "   label: C1 E1 E0 E0 E0 + C22 E0 E0 E0 E2 + C17 E0 E0 E0 E0 [SEP] C1 E0 E1 E0 E0 + C24 E0 E0 E0 E2 + C11 E0 E0 E0 E1 + C22 E0 E0 E0 E0 [SEP] C1 E0 E0 E1 E0 + C13 E0 E0 E0 E2 + C8 E0 E0 E0 E1 + C7 E0 E0 E0 E0 [SEP] C1 E0 E0 E0 E3\n",
      "\n",
      "\n",
      "[o] pred: C1 E1 E0 E0 E0 + C17 E0 E0 E0 E0 [SEP] C1 E0 E1 E0 E0 + C19 E0 E0 E0 E0 [SEP] C1 E0 E0 E1 E0 + C28 E0 E0 E0 E0 [SEP] C1 E0 E0 E0 E1\n",
      "   label: C1 E1 E0 E0 E0 + C17 E0 E0 E0 E0 [SEP] C1 E0 E1 E0 E0 + C19 E0 E0 E0 E0 [SEP] C1 E0 E0 E1 E0 + C28 E0 E0 E0 E0 [SEP] C1 E0 E0 E0 E1\n",
      "\n",
      "\n",
      "[x] pred: C1 E1 E0 E0 E0 + C3 E0 E0 E0 E1 + C21 E0 E0 E0 E0 [SEP] C1 E0 E1 E0 E0 + C4 E0 E0 E0 E1 + C23 E0 E0 E0 E0 [SEP] C1 E0 E0 E1 E0 + C13 E0 E0 E0 E1 + C13 E0 E0 E0 E0 [SEP] C1 E0 E0 E0 E2\n",
      "   label: C1 E1 E0 E0 E0 + C3 E0 E0 E0 E1 + C21 E0 E0 E0 E0 [SEP] C1 E0 E1 E0 E0 + C16 E0 E0 E0 E1 + C23 E0 E0 E0 E0 [SEP] C1 E0 E0 E1 E0 + C13 E0 E0 E0 E1 + C13 E0 E0 E0 E0 [SEP] C1 E0 E0 E0 E2\n",
      "\n",
      "\n",
      "[o] pred: C1 E1 E0 E0 E0 + C20 E0 E0 E0 E0 [SEP] C1 E0 E1 E0 E0 + C10 E0 E0 E0 E3 + C4 E0 E0 E0 E1 [SEP] C1 E0 E0 E1 E0 + C9 E0 E0 E0 E3 + C17 E0 E0 E0 E2 + C7 E0 E0 E0 E1 [SEP] C1 E0 E0 E0 E4\n",
      "   label: C1 E1 E0 E0 E0 + C20 E0 E0 E0 E0 [SEP] C1 E0 E1 E0 E0 + C10 E0 E0 E0 E3 + C4 E0 E0 E0 E1 [SEP] C1 E0 E0 E1 E0 + C9 E0 E0 E0 E3 + C17 E0 E0 E0 E2 + C7 E0 E0 E0 E1 [SEP] C1 E0 E0 E0 E4\n",
      "\n",
      "\n",
      "[o] pred: C1 E1 E0 E0 E0 + C19 E0 E0 E0 E1 [SEP] C1 E0 E1 E0 E0 + C7 E0 E0 E0 E1 [SEP] C1 E0 E0 E1 E0 + C11 E0 E0 E0 E1 [SEP] C1 E0 E0 E0 E2 + C26 E0 E0 E0 E1\n",
      "   label: C1 E1 E0 E0 E0 + C19 E0 E0 E0 E1 [SEP] C1 E0 E1 E0 E0 + C7 E0 E0 E0 E1 [SEP] C1 E0 E0 E1 E0 + C11 E0 E0 E0 E1 [SEP] C1 E0 E0 E0 E2 + C26 E0 E0 E0 E1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hits = []\n",
    "for pt, lt in zip(preds_text, labels_t):\n",
    "    hits.append(pt == lt)\n",
    "    if pt == lt:\n",
    "        print(f'[o] pred: {pt}\\n   label: {lt}\\n\\n')\n",
    "    else:\n",
    "        print(f'[x] pred: {pt}\\n   label: {lt}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5625"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = sum(hits) / len(hits)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C4 E2 E0 + C7 E1 E7 + C4 E1 E6 + C2 E1 E5 + C8 E1 E4 + C30 E1 E3 + C28 E1 E2 + C20 E1 E1 + C9 E1 E0 [SEP] C6 E4 E1 + C26 E3 E8 + C6 E3 E7 + C3 E3 E6 + C12 E3 E5 + C14 E3 E4 + C11 E3 E3 + C30 E3 E2 + C14 E3 E1 + C22 E2 E2 + C5 E2 E1 + C13 E1 E9 + C3 E1 E8 + C17 E1 E7 + C6 E1 E6 + C7 E1 E5 + C21 E1 E4 + C15 E1 E3 + C3 E1 E2 + C1 E0 E5 + C5 E0 E4 + C22 E0 E3 + C30 E0 E2 + C17 E0 E1 [SEP] C16 E4 E3 + C19 E3 E4 + C5 E3 E3 + C24 E3 E2 + C11 E2 E9 + C24 E2 E8 + C12 E2 E7 + C17 E2 E6 + C25 E2 E5 + C17 E2 E4 + C27 E2 E3 + C23 E2 E2 + C10 E2 E0 + C3 E1 E7 + C15 E1 E6 + C27 E1 E5 + C19 E1 E4 + C30 E1 E3 + C8 E1 E2 + C19 E1 E1 + C8 E1 E0 + C10 E0 E0'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C1 E1 E0 + C10 E0 E0 [SEP] C1 E0 E5 + C5 E0 E4 + C22 E0 E3 + C30 E0 E2 + C17 E0 E1'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_t[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.tokernizer import set_tokenizer, set_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_variables = 2\n",
    "field = 'QQ'\n",
    "max_coefficient = 100\n",
    "max_degree=20\n",
    "continous_ids = [2]\n",
    "\n",
    "params = {'encoding_method': 'standard',\n",
    "          'd_model': 256,\n",
    "          'nhead': 4,\n",
    "          'num_encoder_layers': 2,\n",
    "          'num_decoder_layers': 2,\n",
    "          'dim_feedforward': 1024,\n",
    "          'dropout': 0.1,\n",
    "          'max_sequence_length': 512,\n",
    "          'positional_encoding': 'embedding',\n",
    "          'regression_weight': 1.0,\n",
    "          'continuous_coefficient': False, # \n",
    "          'continuous_exponent': False, #\n",
    "          'regression_weights': [1.0], #\n",
    "          'continuous_embedding_model': 'ffn'} #\n",
    "\n",
    "import argparse\n",
    "\n",
    "params = argparse.Namespace(**params)\n",
    "\n",
    "vocab = set_vocab(num_variables, \n",
    "                  field=field, \n",
    "                  max_coeff=max_coefficient, \n",
    "                  max_degree=max_degree, \n",
    "                  continuous_coefficient=False, \n",
    "                continuous_exponent=False)\n",
    "tokenizer = set_tokenizer(vocab)\n",
    "model = load_model(params, 'bart', vocab=vocab, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'shape'\n",
    "encoding = 'hybrid'\n",
    "n, field = 2, 'GF7'\n",
    "data_name = f'{task}_n={n}_field={field}'\n",
    "data_path = f'data/{task}/{data_name}/data_{field}_n={n}.test.lex.infix'\n",
    "\n",
    "testset     = _load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = HybridDataCollator(tokenizer)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, collate_fn=dc, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task = 'shape'\n",
    "# encoding = 'standard'\n",
    "\n",
    "# n, field = 2, 'GF7'\n",
    "# data_name = f'{task}_n={n}_field={field}'\n",
    "# data_path = f'data/{task}/{data_name}/data_{field}_n={n}.test.lex.infix'\n",
    "\n",
    "# data_config_path = f'config/{data_name}.yaml'\n",
    "# _save_path = f'{field}_n={n}_ep=8_bs=16'\n",
    "# save_path = f'results/{task}/{encoding}_embedding/{_save_path}'\n",
    "# # save_path = f'results/{task}/{encoding}/dryrun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in batch:\n",
    "    batch[key] = batch[key].to(model.device) if isinstance(batch[key], torch.Tensor) else batch[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': tensor(19.9327, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'loss_clf': tensor(5.6199, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
       " 'loss_rg': tensor(14.3128, device='cuda:0', grad_fn=<MseLossBackward0>),\n",
       " 'logits': tensor([[[-0.7997,  0.1777, -0.4062,  ...,  0.0946, -0.1072, -0.6497],\n",
       "          [ 0.1215,  0.7225, -0.7747,  ...,  1.2960, -0.0859, -0.2309],\n",
       "          [-0.5851, -0.0074, -0.6108,  ..., -0.1392,  0.0496, -1.0368],\n",
       "          ...,\n",
       "          [-0.2318,  0.3845, -1.1978,  ...,  0.1619, -0.4243,  1.0051],\n",
       "          [-0.5707,  0.4581, -0.5036,  ...,  0.0650, -0.1025,  0.2354],\n",
       "          [-0.5423, -0.5598, -0.8385,  ...,  0.3655,  1.3766, -0.0080]],\n",
       " \n",
       "         [[-0.8181, -0.0689, -0.1057,  ..., -0.0082, -0.4242, -0.6536],\n",
       "          [ 0.0495,  0.5423, -0.7644,  ...,  1.3736, -0.0865, -0.0540],\n",
       "          [-0.6605,  0.0864, -0.4809,  ..., -0.0854,  0.1100, -1.1429],\n",
       "          ...,\n",
       "          [-0.3453,  0.0089, -1.0978,  ...,  0.1233, -0.3788,  0.5984],\n",
       "          [-0.4874,  0.4503, -0.5650,  ...,  0.1287, -0.1283, -0.0689],\n",
       "          [-0.5728, -1.0142, -0.5861,  ...,  0.5620,  1.4657, -0.1066]],\n",
       " \n",
       "         [[-0.8225, -0.0807, -0.1729,  ...,  0.1287, -0.2278, -0.7739],\n",
       "          [ 0.0758,  0.7071, -0.8730,  ...,  1.4156, -0.2210, -0.3481],\n",
       "          [-0.8861, -0.0824, -0.7213,  ..., -0.0173, -0.0724, -0.8789],\n",
       "          ...,\n",
       "          [-0.0940,  0.2687, -0.9500,  ...,  0.0359, -0.1886,  0.8044],\n",
       "          [-0.8698,  0.4918, -0.4392,  ..., -0.0153, -0.3165,  0.0926],\n",
       "          [-0.3844, -0.7870, -0.6984,  ...,  0.5331,  1.5219,  0.0384]],\n",
       " \n",
       "         [[-0.6994, -0.1238, -0.2941,  ...,  0.0596, -0.1919, -0.6383],\n",
       "          [ 0.1102,  0.8171, -0.8330,  ...,  1.4833,  0.0372, -0.1265],\n",
       "          [-0.6337,  0.0302, -0.6471,  ..., -0.0646, -0.0414, -1.2111],\n",
       "          ...,\n",
       "          [ 0.7313,  0.1775, -0.9483,  ...,  1.1919,  0.1462,  1.1392],\n",
       "          [-0.3535, -0.0594, -0.1381,  ...,  0.4037, -0.4380, -0.0994],\n",
       "          [-0.6271, -1.2578, -0.3535,  ...,  0.8152,  1.3734, -0.6833]]],\n",
       "        device='cuda:0', grad_fn=<ViewBackward0>),\n",
       " 'logits_for_regression': tensor([[[ 0.4625],\n",
       "          [ 1.1253],\n",
       "          [ 0.8932],\n",
       "          [-0.0898],\n",
       "          [-0.3464],\n",
       "          [ 0.3922],\n",
       "          [-0.6745],\n",
       "          [-0.2959],\n",
       "          [-0.3283],\n",
       "          [ 0.3412],\n",
       "          [-0.1999],\n",
       "          [-0.1936],\n",
       "          [-0.3279],\n",
       "          [ 0.3187],\n",
       "          [-0.2966],\n",
       "          [-0.0313],\n",
       "          [ 0.4524],\n",
       "          [ 0.5010],\n",
       "          [-0.6834],\n",
       "          [ 0.2558],\n",
       "          [ 0.4120],\n",
       "          [-0.5448],\n",
       "          [-0.8082],\n",
       "          [ 0.2053],\n",
       "          [-0.2170],\n",
       "          [ 0.6189],\n",
       "          [ 0.0466],\n",
       "          [-0.4912],\n",
       "          [ 0.1762],\n",
       "          [ 0.3051],\n",
       "          [ 0.0974],\n",
       "          [-0.4219]],\n",
       " \n",
       "         [[ 0.7257],\n",
       "          [ 1.1566],\n",
       "          [ 0.6295],\n",
       "          [-0.5771],\n",
       "          [-0.1743],\n",
       "          [ 0.3086],\n",
       "          [-0.9648],\n",
       "          [-0.0110],\n",
       "          [-0.2449],\n",
       "          [ 0.5497],\n",
       "          [-0.0265],\n",
       "          [-0.3618],\n",
       "          [-0.5325],\n",
       "          [ 0.2615],\n",
       "          [-0.4668],\n",
       "          [-0.3232],\n",
       "          [ 0.0197],\n",
       "          [ 0.5353],\n",
       "          [-0.4306],\n",
       "          [ 0.1355],\n",
       "          [ 0.2649],\n",
       "          [-0.5547],\n",
       "          [-0.9938],\n",
       "          [-0.1436],\n",
       "          [-0.2187],\n",
       "          [ 0.5986],\n",
       "          [ 0.1305],\n",
       "          [-0.3140],\n",
       "          [-0.1057],\n",
       "          [ 0.6423],\n",
       "          [ 0.1783],\n",
       "          [-0.3037]],\n",
       " \n",
       "         [[ 0.4225],\n",
       "          [ 1.1209],\n",
       "          [ 0.5867],\n",
       "          [-0.1844],\n",
       "          [-0.3613],\n",
       "          [ 0.1198],\n",
       "          [-0.7983],\n",
       "          [-0.6768],\n",
       "          [-0.2910],\n",
       "          [ 0.3985],\n",
       "          [-0.2072],\n",
       "          [ 0.2356],\n",
       "          [-0.3958],\n",
       "          [ 0.4437],\n",
       "          [-0.1831],\n",
       "          [-0.0213],\n",
       "          [ 0.3101],\n",
       "          [ 0.3396],\n",
       "          [-0.5407],\n",
       "          [ 0.0490],\n",
       "          [ 0.2819],\n",
       "          [-0.4986],\n",
       "          [-0.8936],\n",
       "          [ 0.0139],\n",
       "          [-0.1311],\n",
       "          [ 0.6600],\n",
       "          [ 0.1081],\n",
       "          [-0.3710],\n",
       "          [ 0.1274],\n",
       "          [ 0.5285],\n",
       "          [ 0.3038],\n",
       "          [-0.5198]],\n",
       " \n",
       "         [[ 0.6475],\n",
       "          [ 1.3006],\n",
       "          [ 0.7569],\n",
       "          [-0.3627],\n",
       "          [-0.1429],\n",
       "          [ 0.1332],\n",
       "          [-1.1839],\n",
       "          [-0.3978],\n",
       "          [-0.5411],\n",
       "          [ 0.3756],\n",
       "          [-0.2121],\n",
       "          [-0.4961],\n",
       "          [-0.6839],\n",
       "          [ 0.1033],\n",
       "          [-0.4021],\n",
       "          [-0.2861],\n",
       "          [-0.2430],\n",
       "          [ 0.4404],\n",
       "          [-0.4574],\n",
       "          [ 0.6430],\n",
       "          [-0.1227],\n",
       "          [-0.5008],\n",
       "          [-1.2832],\n",
       "          [-0.6627],\n",
       "          [-0.4713],\n",
       "          [ 0.4382],\n",
       "          [-0.4398],\n",
       "          [-0.1555],\n",
       "          [-0.4383],\n",
       "          [ 0.1841],\n",
       "          [-0.3641],\n",
       "          [-0.5515]]], device='cuda:0', grad_fn=<ViewBackward0>),\n",
       " 'encoder_output': tensor([[[-1.0871, -0.9027, -1.0456,  ...,  2.1507,  0.2569,  0.3417],\n",
       "          [-0.0500, -0.0966,  0.6812,  ...,  0.0415, -0.2072,  0.8769],\n",
       "          [ 0.9258,  0.0990,  0.3053,  ...,  0.4459, -0.0286,  1.0480],\n",
       "          ...,\n",
       "          [-0.5066, -0.7059, -0.9433,  ...,  0.9339,  0.1780,  0.9655],\n",
       "          [ 0.7728,  0.2820,  0.0788,  ..., -1.2342, -0.3853, -0.0090],\n",
       "          [-0.6788, -0.4927,  0.2889,  ...,  1.3087,  1.3105, -0.4769]],\n",
       " \n",
       "         [[-1.1123, -0.9353, -1.0874,  ...,  1.5304,  0.1625,  0.6548],\n",
       "          [ 0.2740,  0.4918,  0.3134,  ...,  0.6726,  1.6726,  1.6206],\n",
       "          [ 0.9874,  0.2136,  0.3300,  ...,  0.7371, -0.0116,  1.3514],\n",
       "          ...,\n",
       "          [-1.0430, -0.5323, -0.4238,  ...,  0.7596,  0.1106,  1.0727],\n",
       "          [ 0.6165,  0.2448, -0.0190,  ..., -1.6127, -0.3009, -0.0152],\n",
       "          [-0.7605, -0.5280,  0.3837,  ...,  1.2890,  1.3002, -0.7094]],\n",
       " \n",
       "         [[-1.0529, -0.8296, -1.3953,  ...,  2.1331,  0.2836,  0.7182],\n",
       "          [-0.0588,  0.6916,  0.5615,  ...,  0.4994,  1.6001,  1.5735],\n",
       "          [ 0.8428, -0.0654,  0.1801,  ...,  0.6757, -0.3364,  1.3778],\n",
       "          ...,\n",
       "          [-0.6738, -0.5608, -0.5452,  ...,  1.1450,  0.0758,  1.2539],\n",
       "          [ 0.6292,  0.3244,  0.0508,  ..., -1.5323, -0.3021,  0.2706],\n",
       "          [-0.7968, -0.4107,  0.4764,  ...,  1.0717,  1.1997, -0.2350]],\n",
       " \n",
       "         [[-1.5140, -0.8813, -1.4527,  ...,  1.5817,  0.3290,  0.7486],\n",
       "          [-0.6634, -0.4517,  0.3725,  ..., -1.0084, -0.7813, -0.4509],\n",
       "          [ 1.0271,  0.1706,  0.0345,  ...,  0.6736, -0.2753,  1.4597],\n",
       "          ...,\n",
       "          [-0.2307, -0.6011, -0.7214,  ...,  0.9028,  0.5457,  1.8695],\n",
       "          [ 1.2760,  0.6890, -0.0087,  ..., -0.7534,  1.4241,  0.9715],\n",
       "          [ 0.7809,  0.2215, -0.7358,  ...,  1.5649,  0.8565, -1.8107]]],\n",
       "        device='cuda:0', grad_fn=<NativeLayerNormBackward0>)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[231, 136, 136,  ...,  26,  25,  10],\n",
       "         [231,  54, 149,  ..., 170, 151,  89],\n",
       "         [231,  54, 149,  ...,  10, 173,   5],\n",
       "         [231,  54, 186,  ..., 172,  79,  91]], device='cuda:0'),\n",
       " tensor([[inf, inf, inf,  ..., inf, inf, inf],\n",
       "         [inf, inf, inf,  ..., inf, inf, inf],\n",
       "         [inf, inf, inf,  ..., inf, inf, inf],\n",
       "         [inf, inf, inf,  ..., inf, inf, inf]], device='cuda:0'))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.greedy_generate(batch['encoder_input'], \n",
    "                      encoder_input_labels=batch['encoder_input_labels'], \n",
    "                      max_length=500, \n",
    "                      encoder_padding_mask=batch['encoder_padding_mask'], \n",
    "                      continuous_token_ids=torch.tensor([tokenizer.vocab['[C]']]).to(model.device),\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_variables = 2\n",
    "field = 'QQ'\n",
    "max_coefficient = 100\n",
    "max_degree=20\n",
    "continous_ids = [2]\n",
    "\n",
    "params = {'encoding_method': 'standard',\n",
    "          'd_model': 256,\n",
    "          'nhead': 4,\n",
    "          'num_encoder_layers': 2,\n",
    "          'num_decoder_layers': 2,\n",
    "          'dim_feedforward': 1024,\n",
    "          'dropout': 0.1,\n",
    "          'max_sequence_length': 512,\n",
    "          'positional_encoding': 'embedding',\n",
    "          'regression_weight': 1.0,}\n",
    "\n",
    "import argparse\n",
    "\n",
    "params = argparse.Namespace(**params)\n",
    "\n",
    "vocab = set_vocab(num_variables, \n",
    "                  field=field, \n",
    "                  max_coeff=max_coefficient, \n",
    "                  max_degree=max_degree, \n",
    "                  continuous_coefficient=False, \n",
    "                continuous_exponent=False)\n",
    "tokenizer = set_tokenizer(vocab)\n",
    "model = load_model(params, vocab=vocab, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_pretrained_bag' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bag \u001b[38;5;241m=\u001b[39m \u001b[43mload_pretrained_bag\u001b[49m(save_path)\n\u001b[1;32m      2\u001b[0m config, model, tokenizer \u001b[38;5;241m=\u001b[39m bag[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m], bag[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m], bag[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokenizer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_pretrained_bag' is not defined"
     ]
    }
   ],
   "source": [
    "bag = load_pretrained_bag(save_path)\n",
    "config, model, tokenizer = bag['config'], bag['model'], bag['tokenizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:10<00:00,  5.01s/it]\n"
     ]
    }
   ],
   "source": [
    "from loader.data import _load_data\n",
    "from loader.data import SimpleDataCollator\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 500\n",
    "dataloader = data_path\n",
    "disable_tqdm = False\n",
    "max_length = 10000\n",
    "\n",
    "if isinstance(dataloader, str):\n",
    "    dataset = _load_data(dataloader)\n",
    "    dc = SimpleDataCollator(tokenizer)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=dc, shuffle=False)\n",
    "\n",
    "# load model    \n",
    "if isinstance(model, str):\n",
    "    bag = load_pretrained_bag(model)\n",
    "    config, model, tokenizer = bag['config'], bag['model'], bag['tokenizer']\n",
    "else:\n",
    "    assert(tokenizer is not None)\n",
    "\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    hits = []\n",
    "    dataloader = tqdm(dataloader, disable=disable_tqdm)  if not disable_tqdm else dataloader\n",
    "    for batch in dataloader:\n",
    "        max_length = min(max_length, batch['labels'].shape[1] + 1)\n",
    "        outputs = model.greedy_generate(batch['encoder_input'].cuda(), max_length=max_length, encoder_padding_mask=batch['encoder_padding_mask'].cuda())\n",
    "        pred = tokenizer.batch_decode(outputs.cpu().numpy(), skip_special_tokens=True)\n",
    "        target = tokenizer.batch_decode(batch['labels'], skip_special_tokens=True)\n",
    "        \n",
    "        hits += [p == t for p, t in zip(pred, target)]\n",
    "        \n",
    "    ret = {'acc': np.array(hits, dtype=float).mean(), 'hits': hits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.432"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ret['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, True, True, True, False, True, False, True, False]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret['hits'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['encoder_input', 'decoder_input', 'encoder_padding_mask', 'decoder_padding_mask', 'labels'])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch  = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.9 s, sys: 48.1 ms, total: 20.9 s\n",
      "Wall time: 4.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "outputs = model.greedy_generate(batch['encoder_input'].cuda(), \n",
    "                                encoder_attention_mask=None,\n",
    "                                encoder_padding_mask=batch['encoder_padding_mask'].cuda(),\n",
    "                                max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[36,  4, 12, 11, 32,  4, 11, 11, 40,  4, 11, 12, 38, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [36,  4, 12, 11, 32,  4, 11, 13, 40,  4, 11, 14, 32,  5, 11, 13, 32,  5,\n",
       "         11, 12, 32,  5, 11, 11, 38, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [36,  4, 12, 11, 32,  5, 11, 11, 40,  4, 11, 15, 38, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [36,  4, 12, 11, 32,  8, 11, 14, 32,  9, 11, 12, 32,  9, 11, 11, 40,  4,\n",
       "         11, 15, 32,  9, 11, 14, 32,  8, 11, 13, 32,  8, 11, 12, 38, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36]], device='cuda:0')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4, 12, 11, 32,  4, 11, 11, 40,  4, 11, 12, 38, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [ 4, 12, 11, 32,  4, 11, 13, 40,  4, 11, 14, 32,  8, 11, 11, 38, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [ 4, 12, 11, 32,  5, 11, 11, 40,  4, 11, 15, 38, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36],\n",
       "        [ 4, 12, 11, 32,  8, 11, 14, 32,  9, 11, 12, 32,  9, 11, 11, 40,  4, 11,\n",
       "         15, 32,  9, 11, 14, 32,  8, 11, 13, 32,  8, 11, 12, 38, 36, 36, 36, 36,\n",
       "         36, 36, 36, 36, 36, 36, 36, 36]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels'][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C1 E1 E0 + C1 E0 E2 [SEP] C1 E0 E3 + C2 E0 E2 + C2 E0 E1 + C2 E0 E0'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(outputs.cpu().numpy(), skip_special_tokens=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C1 E1 E0 + C1 E0 E2 [SEP] C1 E0 E3 + C5 E0 E0'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(batch['labels'], skip_special_tokens=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C1 E1 E0 + C1 E0 E2 [SEP] C1 E3 E1 + C1 E2 E3 + C5 E2 E2 + C5 E1 E4 + C1 E1 E2 + C5 E1 E1 + C3 E1 E0 + C6 E0 E3 + C3 E0 E2 + C2 E0 E1 + C5 E0 E0 [SEP] C4 E5 E2 + C4 E4 E4 + C4 E4 E1 + C4 E3 E3 + C6 E3 E2 + C5 E3 E1 + C3 E2 E5 + C3 E2 E4 + C5 E2 E3 + C3 E2 E1 + C1 E2 E0 + C2 E1 E4 + C1 E1 E3 + C1 E1 E2 + C2 E0 E4 + C5 E0 E3 + C1 E0 E2 + C3 E0 E1 + C2 E0 E0'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(batch['encoder_input'], skip_special_tokens=True)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'E9': 20,\n",
       " 'C0': 3,\n",
       " 'E12': 23,\n",
       " '[UNK]': 41,\n",
       " '/': 35,\n",
       " 'E10': 21,\n",
       " 'E2': 13,\n",
       " 'C2': 5,\n",
       " 'E17': 28,\n",
       " '[SEP]': 40,\n",
       " '^': 34,\n",
       " 'E14': 25,\n",
       " 'E18': 29,\n",
       " '</s>': 38,\n",
       " '<s>': 37,\n",
       " 'E3': 14,\n",
       " '+': 32,\n",
       " 'C3': 6,\n",
       " 'E8': 19,\n",
       " 'E13': 24,\n",
       " 'E0': 11,\n",
       " 'E5': 16,\n",
       " '[PAD]': 36,\n",
       " 'E4': 15,\n",
       " 'C4': 7,\n",
       " 'E20': 31,\n",
       " 'C1': 4,\n",
       " 'C5': 8,\n",
       " '[C]': 2,\n",
       " 'C6': 9,\n",
       " '[E]': 10,\n",
       " 'E19': 30,\n",
       " '[CLS]': 39,\n",
       " '*': 33,\n",
       " 'E16': 27,\n",
       " 'E1': 12,\n",
       " 'E11': 22,\n",
       " 'x0': 0,\n",
       " 'x1': 1,\n",
       " 'E15': 26,\n",
       " 'E7': 18,\n",
       " 'E6': 17}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
