{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/kera/workspace/Transformer-GB\n"
     ]
    }
   ],
   "source": [
    "%cd \"/home/kera/workspace/Transformer-GB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import yaml \n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import argparse\n",
    "import re \n",
    "from transformers import AutoModelForSeq2SeqLM, AutoConfig\n",
    "\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from src.loader.data import load_data\n",
    "from src.loader.checkpoint import load_trained_bag\n",
    "from src.evalution.evaluators import eval_prediction\n",
    "\n",
    "load('src/data/symbolic_utils.sage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def get_random_MQsystem(n, m, ring):\n",
    "    ring = PolynomialRing(GF(2), 'x', n, order='lex')\n",
    "    F = [ring.random_element(degree=2, terms=Infinity) for _ in range(m)]\n",
    "\n",
    "    x = [ring.base_ring().random_element() for _ in range(n)]\n",
    "    eps = [f(x) for f in F]\n",
    "    F = [ring(f - e) for f, e in zip(F, eps)]\n",
    "    F = ideal(F).basis\n",
    "\n",
    "    assert all(f(x) == 0 for f in F)\n",
    "\n",
    "    return F, x\n",
    "\n",
    "def sol_to_gb(ring, sol):\n",
    "    G = [ring(xi - s) for xi, s in zip(ring.gens(), sol)]\n",
    "    return ideal(G).basis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def generate_MQ_dataset(n, m, num_samples=1000):\n",
    "    ring = PolynomialRing(GF(2), 'x', n, order='lex')\n",
    "\n",
    "    dataset = []\n",
    "    for _ in range(num_samples):\n",
    "        F, x = get_random_MQsystem(n, m, ring)\n",
    "        G = sol_to_gb(ring, x)\n",
    "        G, \n",
    "        dataset.append((F, G, x))\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def experiement(field, n, load_dir, num_beams=1):\n",
    "    bag = load_trained_bag(load_dir, from_checkpoint=True)\n",
    "    model = bag['model'] \n",
    "    tokenizer = bag['tokenizer']\n",
    "    params = bag['params']\n",
    "    \n",
    "    F, G = load_katsura(field, n)\n",
    "    F_prefix = [poly_to_prefix(f) for f in F]\n",
    "    G_prefix = [poly_to_prefix(g) for g in G]\n",
    "    x_text = ' [SEP] '.join(F_prefix)\n",
    "    y_text = ' [SEP] '.join(G_prefix)\n",
    "\n",
    "    x = tokenizer(x_text, return_tensors='pt')['input_ids'].cuda()\n",
    "    # y = tokenizer(y_text, return_tensors='pt')['input_ids'].cuda()\n",
    "    output_ids = model.generate(x, max_length=1000, num_beams=num_beams, do_sample=False)\n",
    "    z_text = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "    G_pred = [prefix_to_poly(zt, F.ring) for zt in z_text[0].split('[SEP]')]\n",
    "    \n",
    "    print(F)\n",
    "    print(G)\n",
    "    print(G_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " field = QQ, n = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The BetterTransformer implementation does not support padding during training, as the fused kernels do not support attention masks. Beware that passing padded batched data during training may result in unexpected outputs. Please refer to https://huggingface.co/docs/optimum/bettertransformer/overview for more details.\n"
     ]
    }
   ],
   "source": [
    "field = 'QQ'\n",
    "n = 5\n",
    "print(f' field = {field}, n = {n}')\n",
    "load_dir = f'results/shape_gb_lex/gb_dataset_n={n}_field={field}'\n",
    "\n",
    "bag = load_trained_bag(load_dir, from_checkpoint=True)\n",
    "model = bag['model'] \n",
    "tokenizer = bag['tokenizer']\n",
    "params = bag['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "m = 2*n\n",
    "dataset = generate_MQ_dataset(n, m, num_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "F, G, sol = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def sol_listform(sol):\n",
    "    return list(sol.values())[::-1]\n",
    "\n",
    "def print_solution(sols, ring):\n",
    "    gens = ring.gens()\n",
    "    for s in sols:\n",
    "        print([s[x] for x in gens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "ring = PolynomialRing(GF(2), 'x', n)\n",
    "qring = PolynomialRing(QQ, 'x', n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:39<00:00,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "bitwise acc    : 0.47\n",
      "rev_bitwise acc: 0.44\n",
      "full acc       : 0.06\n",
      "no solution    : 94/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_beams = 1\n",
    "\n",
    "bitwise_acc = 0\n",
    "rev_bitwise_acc = 0\n",
    "full_acc = 0\n",
    "num_samples = 1000 # len(dataset)\n",
    "no_solution = 0\n",
    "\n",
    "num_test_samples = min(1000, num_samples)\n",
    "for F, G, sol in tqdm(dataset[:num_test_samples]):\n",
    "    F_prefix = [poly_to_prefix(f) for f in F]\n",
    "    G_prefix = [poly_to_prefix(g) for g in G]\n",
    "    x_text = ' [SEP] '.join(F_prefix)\n",
    "    y_text = ' [SEP] '.join(G_prefix)\n",
    "\n",
    "    x = tokenizer(x_text, return_tensors='pt')['input_ids'].cuda()\n",
    "    # y = tokenizer(y_text, return_tensors='pt')['input_ids'].cuda()\n",
    "    output_ids = model.generate(x, max_length=1000, num_beams=num_beams, do_sample=False)\n",
    "    z_text = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "    G_pred = [prefix_to_poly(zt, qring) for zt in z_text[0].split('[SEP]')]\n",
    "    # print(G_pred)\n",
    "\n",
    "    G_pred = ideal(G_pred).change_ring(ring).basis\n",
    "    pred_solutions = ideal(G_pred).variety()\n",
    "\n",
    "    if pred_solutions:\n",
    "        pred_sol = sol_listform(pred_solutions[0])\n",
    "\n",
    "        bitwise_acc += np.sum(np.array(pred_sol) == np.array(sol))\n",
    "        rev_bitwise_acc += np.sum(np.array(pred_sol) != np.array(sol))\n",
    "        full_hit = np.all(np.array(pred_sol) == np.array(sol))\n",
    "        full_acc    += full_hit\n",
    "\n",
    "        # if full_hit:\n",
    "        #     print(f'solution  : {sol}')\n",
    "        #     print(f'prediction: {pred_sol}')\n",
    "\n",
    "    else:\n",
    "        no_solution += 1\n",
    "\n",
    "bitwise_acc = float(bitwise_acc / (num_test_samples * n))\n",
    "rev_bitwise_acc = float(rev_bitwise_acc / (num_test_samples * n))\n",
    "full_acc    = float(full_acc / num_test_samples)\n",
    "\n",
    "print('----------------------')\n",
    "print(f'bitwise acc    : {bitwise_acc:.2f}')\n",
    "print(f'rev_bitwise acc: {rev_bitwise_acc:.2f}')\n",
    "print(f'full acc       : {full_acc:.2f}')\n",
    "print(f'no solution    : {no_solution}/{num_test_samples}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- G (answer) --------\n",
      "x0\n",
      "x1\n",
      "x2 + 1\n",
      "x3\n",
      "x4 + 1\n",
      "- G (Transformer) --------\n",
      "x0 + x4 + 1\n",
      "x1 + x4 + 1\n",
      "x2 + x4 + 1\n",
      "x3 + x4 + 1\n",
      "x4^2\n",
      "\n",
      "- G (answer) --------\n",
      "x0\n",
      "x1\n",
      "x2\n",
      "x3 + 1\n",
      "x4\n",
      "- G (Transformer) --------\n",
      "x0 + x4 + 1\n",
      "x4^2 + x1 + 1\n",
      "x4^2 + x2\n",
      "x3 + x4 + 1\n",
      "x4^3 + x4^2\n",
      "\n",
      "- G (answer) --------\n",
      "x0 + 1\n",
      "x1\n",
      "x2\n",
      "x3\n",
      "x4\n",
      "- G (Transformer) --------\n",
      "x0 + x4 + 1\n",
      "x1 + x4 + 1\n",
      "x2 + x4 + 1\n",
      "x3 + 1\n",
      "x4^2 + x4\n",
      "\n",
      "- G (answer) --------\n",
      "x0\n",
      "x1\n",
      "x2 + 1\n",
      "x3\n",
      "x4 + 1\n",
      "- G (Transformer) --------\n",
      "x0 + x4 + 1\n",
      "x1 + x4 + 1\n",
      "x2 + 1\n",
      "x3 + x4 + 1\n",
      "x4^2 + 1\n",
      "\n",
      "- G (answer) --------\n",
      "x0 + 1\n",
      "x1 + 1\n",
      "x2 + 1\n",
      "x3\n",
      "x4 + 1\n",
      "- G (Transformer) --------\n",
      "x0 + x4 + 1\n",
      "x1 + x4 + 1\n",
      "x2 + x4 + 1\n",
      "x3 + x4\n",
      "x4^2\n",
      "\n",
      "- G (answer) --------\n",
      "x0 + 1\n",
      "x1 + 1\n",
      "x2\n",
      "x3\n",
      "x4\n",
      "- G (Transformer) --------\n",
      "x0 + x4 + 1\n",
      "x1 + x4\n",
      "x2 + x4 + 1\n",
      "x3 + 1\n",
      "x4^2\n",
      "\n",
      "- G (answer) --------\n",
      "x0 + 1\n",
      "x1 + 1\n",
      "x2 + 1\n",
      "x3\n",
      "x4\n",
      "- G (Transformer) --------\n",
      "x0 + x4 + 1\n",
      "x1 + x4\n",
      "x2 + 1\n",
      "x3 + x4\n",
      "x4^2 + x4\n",
      "\n",
      "- G (answer) --------\n",
      "x0\n",
      "x1 + 1\n",
      "x2 + 1\n",
      "x3\n",
      "x4 + 1\n",
      "- G (Transformer) --------\n",
      "x0 + x4\n",
      "x1 + x4 + 1\n",
      "x2 + x4 + 1\n",
      "x3 + x4\n",
      "x4^2\n",
      "\n",
      "- G (answer) --------\n",
      "x0\n",
      "x1\n",
      "x2 + 1\n",
      "x3 + 1\n",
      "x4\n",
      "- G (Transformer) --------\n",
      "x0 + x4 + 1\n",
      "x1 + x4 + 1\n",
      "x2 + x4 + 1\n",
      "x3 + x4 + 1\n",
      "x4^2\n",
      "\n",
      "- G (answer) --------\n",
      "x0\n",
      "x1\n",
      "x2\n",
      "x3\n",
      "x4 + 1\n",
      "- G (Transformer) --------\n",
      "x0 + x4 + 1\n",
      "x1 + x4 + 1\n",
      "x2 + x4 + 1\n",
      "x3 + x4\n",
      "x4^2 + 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_beams = 1\n",
    "\n",
    "bitwise_acc = 0\n",
    "rev_bitwise_acc = 0\n",
    "full_acc = 0\n",
    "num_samples = 1000 # len(dataset)\n",
    "no_solution = 0\n",
    "\n",
    "num_test_samples = min(10, num_samples)\n",
    "for F, G, sol in tqdm(dataset[:num_test_samples], disable=True):\n",
    "    F_prefix = [poly_to_prefix(f) for f in F]\n",
    "    G_prefix = [poly_to_prefix(g) for g in G]\n",
    "    x_text = ' [SEP] '.join(F_prefix)\n",
    "    y_text = ' [SEP] '.join(G_prefix)\n",
    "\n",
    "    x = tokenizer(x_text, return_tensors='pt')['input_ids'].cuda()\n",
    "    # y = tokenizer(y_text, return_tensors='pt')['input_ids'].cuda()\n",
    "    output_ids = model.generate(x, max_length=1000, num_beams=num_beams, do_sample=False)\n",
    "    z_text = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "    G_pred = [prefix_to_poly(zt, qring) for zt in z_text[0].split('[SEP]')]\n",
    "    # print(G_pred)\n",
    "\n",
    "    G_pred = ideal(G_pred).change_ring(ring).basis\n",
    "\n",
    "    print('- G (answer) --------')\n",
    "    for g in G: print(g)\n",
    "    print('- G (Transformer) --------')\n",
    "    for g in G_pred: print(g)\n",
    "\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "m = n+1\n",
    "dataset = generate_MQ_dataset(n, m, num_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-f\n"
     ]
    }
   ],
   "source": [
    "load('src/data/gbdataset.sage')\n",
    "\n",
    "F, G, sol = dataset[0]\n",
    "F, G = ideal(F).change_ring(qring).basis, ideal(G).change_ring(qring).basis\n",
    "F, G = matrix(F).T, matrix(G).T\n",
    "\n",
    "# builder = GBDataset_Builder(qring, \n",
    "#                             max_rand_coeff=3, \n",
    "#                             max_coeff=-1,\n",
    "#                             max_size=6, \n",
    "#                             max_degree=4, \n",
    "#                             max_num_terms=None, \n",
    "#                             min_num_terms=1, \n",
    "#                             max_Gdegree=4, \n",
    "#                             max_num_Gterms=None, \n",
    "#                             num_duplicants=1, \n",
    "#                             density=1.0, \n",
    "#                             with_permutation=True)\n",
    "\n",
    "builder = GBDataset_Builder(qring, \n",
    "                            max_rand_coeff=3, \n",
    "                            max_coeff=-1,\n",
    "                            max_size=6, \n",
    "                            max_degree=4, \n",
    "                            max_num_terms=None, \n",
    "                            min_num_terms=1, \n",
    "                            max_Gdegree=4, \n",
    "                            max_num_Gterms=None, \n",
    "                            num_duplicants=1, \n",
    "                            density=1.0, \n",
    "                            with_permutation=True)\n",
    "\n",
    "# num_vars = F.nrows()\n",
    "# m = num_vars\n",
    "m = F.nrows()\n",
    "max_degree = 3\n",
    "density = 0.2\n",
    "d = None\n",
    "# m = randint(0, max_size-num_vars) + num_vars\n",
    "# d = randint(min_num_terms, max_num_terms) if max_num_terms is not None else None \n",
    "# A = builder.random_umut_matrix(n, F.nrows(),  degree=max_degree, terms=d, density=density, num_bound=builder.max_rand_coeff)\n",
    "U = builder.random_umut_matrix(m, m, degree=max_degree, terms=d, density=density, num_bound=builder.max_rand_coeff)\n",
    "if builder.with_permutation:\n",
    "    P = random_permutation_matrix(m) \n",
    "    U = U * P\n",
    "\n",
    "F_new = U * F\n",
    "F_new = [f[0] for f in F_new]\n",
    "G     = [g[0] for g in G]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Gröbner basis (answer) ------------\n",
      "g_0 = x0\n",
      "g_1 = x1 + 1\n",
      "g_2 = x2 + 1\n",
      "g_3 = x3\n",
      "g_4 = x4 + 1\n",
      "\n",
      "-- Gröbner basis (Transformer) -------\n",
      "g_0 = x0 + x4 + 1\n",
      "g_1 = x1 + x4\n",
      "g_2 = x2 - 1/3*x4 + 1\n",
      "g_3 = x3 + x4\n",
      "g_4 = x4^2 - 2*x4\n",
      "\n",
      " 1 solutions found.\n",
      "[1, 0, 1, 0, 0]\n",
      "(True solution is [0, 1, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "num_beams = 1\n",
    "\n",
    "F_prefix = [poly_to_prefix(f) for f in F_new]\n",
    "G_prefix = [poly_to_prefix(g) for g in G]\n",
    "x_text = ' [SEP] '.join(F_prefix)\n",
    "y_text = ' [SEP] '.join(G_prefix)\n",
    "\n",
    "x = tokenizer(x_text, return_tensors='pt')['input_ids'].cuda()\n",
    "# y = tokenizer(y_text, return_tensors='pt')['input_ids'].cuda()\n",
    "output_ids = model.generate(x, max_length=1000, num_beams=num_beams, do_sample=False)\n",
    "z_text = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "G_pred = [prefix_to_poly(zt, qring) for zt in z_text[0].split('[SEP]')]\n",
    "\n",
    "print('-- Gröbner basis (answer) ------------')\n",
    "for i, g in enumerate(G): print(f'g_{i} = {g}')\n",
    "print('')\n",
    "\n",
    "print('-- Gröbner basis (Transformer) -------')\n",
    "for i, g in enumerate(G_pred): print(f'g_{i} = {g}')\n",
    "print('')\n",
    "\n",
    "\n",
    "sols = ideal(G_pred).change_ring(ring).variety()\n",
    "print(f' {len(sols)} solutions found.')\n",
    "print_solution(sols, ring)\n",
    "\n",
    "print(f'(True solution is {sol})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "ring = PolynomialRing(GF(2), 'x', n)\n",
    "qring = PolynomialRing(GF(7), 'x', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " field = F7, n = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The BetterTransformer implementation does not support padding during training, as the fused kernels do not support attention masks. Beware that passing padded batched data during training may result in unexpected outputs. Please refer to https://huggingface.co/docs/optimum/bettertransformer/overview for more details.\n"
     ]
    }
   ],
   "source": [
    "field = 'F7'\n",
    "n = 5\n",
    "print(f' field = {field}, n = {n}')\n",
    "load_dir = f'results/shape_gb_lex/gb_dataset_n={n}_field={field}'\n",
    "\n",
    "bag = load_trained_bag(load_dir, from_checkpoint=True)\n",
    "model = bag['model'] \n",
    "tokenizer = bag['tokenizer']\n",
    "params = bag['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "m = 2*n\n",
    "dataset = generate_MQ_dataset(n, m, num_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 4/300 [00:00<01:13,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution  : [0, 0, 1, 0, 1]\n",
      "prediction: [0, 0, 1, 0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 19/300 [00:04<01:04,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution  : [0, 0, 0, 0, 1]\n",
      "prediction: [0, 0, 0, 0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 28/300 [00:06<01:00,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution  : [0, 0, 0, 0, 0]\n",
      "prediction: [0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 53/300 [00:11<00:57,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution  : [0, 1, 0, 1, 1]\n",
      "prediction: [0, 1, 0, 1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 55/300 [00:12<00:53,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution  : [0, 0, 0, 0, 0]\n",
      "prediction: [0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 64/300 [00:14<00:48,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution  : [0, 0, 0, 0, 0]\n",
      "prediction: [0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 112/300 [00:25<00:43,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution  : [0, 0, 0, 0, 0]\n",
      "prediction: [0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 121/300 [00:27<00:42,  4.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution  : [1, 1, 0, 0, 1]\n",
      "prediction: [1, 1, 0, 0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 145/300 [00:32<00:34,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution  : [1, 0, 0, 0, 1]\n",
      "prediction: [1, 0, 0, 0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 154/300 [00:34<00:37,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution  : [0, 0, 0, 0, 0]\n",
      "prediction: [0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 179/300 [00:40<00:27,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution  : [0, 0, 0, 0, 1]\n",
      "prediction: [0, 0, 0, 0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 226/300 [00:50<00:14,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution  : [0, 0, 0, 0, 1]\n",
      "prediction: [0, 0, 0, 0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 232/300 [00:51<00:11,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution  : [1, 0, 1, 0, 0]\n",
      "prediction: [1, 0, 1, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 256/300 [00:55<00:07,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution  : [1, 0, 0, 0, 0]\n",
      "prediction: [1, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 260/300 [00:56<00:08,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution  : [0, 0, 0, 0, 0]\n",
      "prediction: [0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 280/300 [01:01<00:04,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution  : [0, 0, 0, 0, 0]\n",
      "prediction: [0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 288/300 [01:02<00:02,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution  : [0, 0, 0, 0, 0]\n",
      "prediction: [0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 290/300 [01:03<00:02,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution  : [0, 0, 0, 0, 1]\n",
      "prediction: [0, 0, 0, 0, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 296/300 [01:04<00:00,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solution  : [0, 0, 1, 1, 1]\n",
      "prediction: [0, 0, 1, 1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:05<00:00,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "bitwise acc    : 0.47\n",
      "full acc       : 0.06\n",
      "no solution    : 24/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_beams = 1\n",
    "\n",
    "bitwise_acc = 0\n",
    "rev_bitwise_acc = 0\n",
    "full_acc = 0\n",
    "num_samples = len(dataset)\n",
    "no_solution = 0\n",
    "\n",
    "num_test_samples = min(1000, num_samples)\n",
    "for F, G, sol in tqdm(dataset[:num_test_samples]):\n",
    "    F_prefix = [poly_to_prefix(f) for f in F]\n",
    "    G_prefix = [poly_to_prefix(g) for g in G]\n",
    "    x_text = ' [SEP] '.join(F_prefix)\n",
    "    y_text = ' [SEP] '.join(G_prefix)\n",
    "\n",
    "    x = tokenizer(x_text, return_tensors='pt')['input_ids'].cuda()\n",
    "    # y = tokenizer(y_text, return_tensors='pt')['input_ids'].cuda()\n",
    "    output_ids = model.generate(x, max_length=1000, num_beams=num_beams, do_sample=False)\n",
    "    z_text = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "    G_pred = [prefix_to_poly(zt, qring) for zt in z_text[0].split('[SEP]')]\n",
    "    # print(G_pred)\n",
    "\n",
    "    G_pred = ideal(G_pred).change_ring(ring).basis\n",
    "    pred_solutions = ideal(G_pred).variety()\n",
    "\n",
    "    if pred_solutions:\n",
    "        pred_sol = sol_listform(pred_solutions[0])\n",
    "\n",
    "        bitwise_acc += np.sum(np.array(pred_sol) == np.array(sol))\n",
    "        rev_bitwise_acc += np.sum(np.array(pred_sol) != np.array(sol))\n",
    "\n",
    "        full_hit = np.all(np.array(pred_sol) == np.array(sol))\n",
    "        full_acc    += full_hit\n",
    "\n",
    "        if full_hit:\n",
    "            print(f'solution  : {sol}')\n",
    "            print(f'prediction: {pred_sol}')\n",
    "\n",
    "\n",
    "    else:\n",
    "        no_solution += 1\n",
    "\n",
    "bitwise_acc = float(bitwise_acc / (num_test_samples * n))\n",
    "rev_bitwise_acc = float(rev_bitwise_acc / (num_test_samples * n))\n",
    "full_acc    = float(full_acc / num_test_samples)\n",
    "\n",
    "print('----------------------')\n",
    "print(f'bitwise acc    : {bitwise_acc:.2f}')\n",
    "print(f'full acc       : {full_acc:.2f}')\n",
    "print(f'no solution    : {no_solution}/{num_test_samples}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 10.0",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "sage",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
